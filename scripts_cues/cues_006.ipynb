{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-15 05:50:44.049673: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-15 05:50:45.103553: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2023-09-15 05:50:45.849791: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-09-15 05:50:45.881205: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-09-15 05:50:45.881563: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import sklearn as sk\n",
    "import numpy as np\n",
    "\n",
    "# NLP\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import gensim\n",
    "import gensim.downloader as gdownload\n",
    "\n",
    "# deep learning\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import layers\n",
    "print(tf.config.list_physical_devices('GPU')) # check if gpu is detected\n",
    "from keras import backend as K\n",
    "\n",
    "# visualization\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessin funcs\n",
    "# preprocessing functions\n",
    "\n",
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(\n",
    "    log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "\n",
    "def multiple_replace(arr, replace, source):\n",
    "    for item in arr:\n",
    "        source = re.sub(item, replace, source)\n",
    "\n",
    "    return source\n",
    "\n",
    "\n",
    "def preprocess_txt(txt):\n",
    "    set_stopwords = set(stopwords.words('english'))\n",
    "\n",
    "    # replace stuff\n",
    "    # any words with non-ascii characters\n",
    "    txt = re.sub(r'\\b\\S*[\\x80-\\xFF]\\S*\\b', ' ', txt)\n",
    "    txt = re.sub(\n",
    "        r'((http|https)\\:\\/\\/)?[a-zA-Z0-9\\.\\/\\?\\:@\\-_=#]+\\.([a-zA-Z]){2,6}([a-zA-Z0-9\\.\\&\\/\\?\\:@\\-_=#])*', ' url ', txt)  # urls\n",
    "    txt = re.sub(\n",
    "        r'\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,7}\\b', ' email ', txt)  # emails\n",
    "    txt = re.sub(r'<.*?>', ' ', txt)  # remove html tags completely\n",
    "    txt = re.sub(r'&.*?;', ' ', txt)  # remove HTML entities\n",
    "    txt = re.sub(r'#', ' ', txt)  # hastags --> just remove the tag\n",
    "    txt = re.sub(r'\\b\\d+\\b', ' num ', txt)  # numbers\n",
    "    txt = re.sub(r'[^\\w\\s]', r' \\g<0> ', txt)  # punctuation\n",
    "\n",
    "    # lowercase\n",
    "    txt = txt.lower()\n",
    "\n",
    "    # https://saturncloud.io/blog/reshaping-text-data-for-lstm-models-in-keras-a-comprehensive-guide/\n",
    "\n",
    "    # split\n",
    "    # nltk handles all punctuation as features\n",
    "    word_arr = re.split(f'\\s+', txt)  # returns list of words\n",
    "\n",
    "    # remove stopwords and drop empty strings\n",
    "    word_arr = [\n",
    "        word for word in word_arr if word not in set_stopwords and len(word) != 0]\n",
    "\n",
    "    # lemmatize\n",
    "    lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "    word_arr = [lemmatizer.lemmatize(word) for word in word_arr]\n",
    "\n",
    "    return word_arr\n",
    "\n",
    "def dataset_to_numpy(df, colnames):\n",
    "    df_dropped = df.drop([x for x in df.columns if x not in colnames], axis = 1)\n",
    "    return df_dropped.to_numpy()\n",
    "\n",
    "def preprocess_txt_list(txt_list, embedding, BODY_LENgth):\n",
    "\n",
    "    processed_tweets = []\n",
    "    for i, txt in enumerate(txt_list):\n",
    "\n",
    "        # DEBUG\n",
    "        try:\n",
    "            _ = txt.lower()\n",
    "        except:\n",
    "            \"Empty string found\"\n",
    "            txt = \"\"\n",
    "\n",
    "        word_list = preprocess_txt(txt)\n",
    "        processed_tweets.append(word_list)\n",
    "\n",
    "        if i % 10000 == 0:  # log the processed message in specified intervals\n",
    "            print(f\"Processed text #{i}:\", word_list)\n",
    "            print(\"---------------------------\")\n",
    "\n",
    "    # tokenize (I ditched the old tokenizer)\n",
    "    print(\"tokenizing...\")\n",
    "    embedding_length = len(embedding)\n",
    "    # convert each word to its index. if it doesn't exist, set it to the last index. I don't care that it ruins one word's meaning\n",
    "    tokenized = [[embedding.key_to_index[word] if word in embedding else (\n",
    "        embedding_length - 1) for word in split_sentence] for split_sentence in processed_tweets]\n",
    "\n",
    "    # add padding and convert to numpy array\n",
    "    print('padding sequences...')\n",
    "    tokenized = np.asarray(keras.preprocessing.sequence.pad_sequences(\n",
    "        tokenized,\n",
    "        padding='post',\n",
    "        maxlen=BODY_LENgth,\n",
    "    ))\n",
    "\n",
    "    # DEBUG\n",
    "    print(tokenized)\n",
    "    print('feature vector shape:', tokenized.shape)\n",
    "\n",
    "    return tokenized\n",
    "\n",
    "# preprocess annotations for initial binary classification\n",
    "\n",
    "def dataset_to_numpy(df, colnames):\n",
    "    df_dropped = df.drop([x for x in df.columns if x not in colnames], axis = 1)\n",
    "    return df_dropped.to_numpy()\n",
    "\n",
    "def preprocess_annotations(annotation_list):\n",
    "    # set all \"threat\" to 1, the rest to 0\n",
    "    return np.asarray([1 if x in [\"Phishing\", \"Phishing Email\"] else 0 for x in annotation_list])\n",
    "\n",
    "# note: this takes already shuffled data\n",
    "def train_valid_test_split(ds, train_ratio, valid_ratio, batch_size):\n",
    "    if type(ds) is list: # if array, assuming they're in array / np array format\n",
    "\n",
    "        # print(type(ds), len(ds)) # DEBUG\n",
    "\n",
    "        # just to be sure they're numpy...\n",
    "        for i in range(len(ds)):\n",
    "            ds[i] = np.asarray(ds[i])\n",
    "\n",
    "        init_len = len(ds[0])\n",
    "        num_train = int(init_len * train_ratio)\n",
    "        num_valid = int(init_len * valid_ratio)\n",
    "\n",
    "        # print(type(ds), len(ds)) # DEBUG\n",
    "\n",
    "        train_ds = [sublist[:num_train] for sublist in ds]\n",
    "        #     ds[0][:num_train],\n",
    "        #     ds[1][:num_train]\n",
    "        # ]\n",
    "\n",
    "        # print(type(train_ds), len(train_ds)) # DEBUG\n",
    "\n",
    "        valid_ds = [sublist[num_train : num_train + num_valid] for sublist in ds]\n",
    "        #     ds[0][num_train : num_train + num_valid],\n",
    "        #     ds[1][num_train : num_train + num_valid]\n",
    "        # ]\n",
    "\n",
    "        # print(type(valid_ds), len(valid_ds)) # DEBUG\n",
    "\n",
    "        test_ds = [sublist[num_train + num_valid :] for sublist in ds]\n",
    "        #     ds[0][num_train + num_valid :],\n",
    "        #     ds[1][num_train + num_valid :]\n",
    "        # ]\n",
    "\n",
    "        # print(type(test_ds), len(test_ds)) # DEBUG\n",
    "\n",
    "        print(f'train ds has {len(train_ds[0])} items.')\n",
    "        print(f'valid ds has {len(valid_ds[0])} items.')\n",
    "        print(f'test ds has {len(test_ds[0])} items.')\n",
    "        \n",
    "    else: # if not array, we assume it's in dataset format\n",
    "        init_len = len(ds)\n",
    "        num_train = int(init_len * train_ratio)\n",
    "        num_valid = int(init_len * valid_ratio)\n",
    "\n",
    "        train_ds = ds.take(num_train).batch(batch_size)\n",
    "        valid_ds = ds.skip(num_train).take(num_valid).batch(batch_size)\n",
    "        test_ds = ds.skip(num_train).skip(num_valid).batch(batch_size)\n",
    "\n",
    "        print(f'train ds has {len(train_ds)} items.')\n",
    "        print(f'valid ds has {len(valid_ds)} items.')\n",
    "        print(f'test ds has {len(test_ds)} items.')\n",
    "\n",
    "    return (train_ds, valid_ds, test_ds)\n",
    "\n",
    "def shuffle(nparr, random_state=23):\n",
    "    rng = np.random.RandomState(random_state)  # reset the seed\n",
    "    return rng.permutation(nparr)\n",
    "\n",
    "def train_and_evaluate(model, train_ds, test_ds, epochs, batch_size, attributes, valid_ds=None):\n",
    "    print(model.summary())\n",
    "\n",
    "    if type(train_ds) is tuple:\n",
    "        history = model.fit(\n",
    "            train_ds[0], # x: \n",
    "            train_ds[1], # y\n",
    "            validation_data = valid_ds, # tuples are allowed, ignored if none\n",
    "            epochs = epochs,\n",
    "            batch_size = batch_size\n",
    "        )\n",
    "    else:\n",
    "        history = model.fit(\n",
    "            train_ds,\n",
    "            validation_data=valid_ds,  # ignored if None\n",
    "            epochs=epochs,\n",
    "            batch_size = batch_size\n",
    "        )\n",
    "\n",
    "    # print(\"history keys:\", history.history.keys()) # DEBUG\n",
    "\n",
    "    if valid_ds != None:\n",
    "        # plot losses over time --> shown after training\n",
    "        plt.plot(history.history['vector_accuracy'])\n",
    "        plt.plot(history.history['val_vector_accuracy'])\n",
    "        plt.title('Per-Item Accuracy')\n",
    "        plt.xlabel('epoch')\n",
    "        plt.xlabel('accuracy')\n",
    "        plt.legend(['train', 'val'], loc='upper left')\n",
    "        plt.grid()\n",
    "        plt.ylim(0.6, 1)\n",
    "        plt.show()\n",
    "\n",
    "        plt.plot(history.history['loss'])\n",
    "        plt.plot(history.history['val_loss'])\n",
    "        plt.title('Loss')\n",
    "        plt.xlabel('epoch')\n",
    "        plt.xlabel('loss')\n",
    "        plt.legend(['train', 'val'], loc='upper left')\n",
    "        plt.grid()\n",
    "        plt.show()\n",
    "\n",
    "        plt.plot(history.history['auc'])\n",
    "        plt.plot(history.history['val_auc'])\n",
    "        plt.title('PR AUC')\n",
    "        plt.xlabel('epoch')\n",
    "        plt.xlabel('AUC')\n",
    "        plt.legend(['train', 'val'], loc='upper left')\n",
    "        plt.grid()\n",
    "        plt.ylim(0.6, 1)\n",
    "        plt.show()\n",
    "\n",
    "    # evaluate\n",
    "    evaluation = model.evaluate(\n",
    "        test_ds[0], # x\n",
    "        test_ds[1], # y\n",
    "        batch_size = batch_size,\n",
    "    )\n",
    "    accuracy = evaluation[1]\n",
    "\n",
    "    # NOTE: \n",
    "    # with the transformer model, test_ds is in the form `[[email_titles, email_bodies], y]`\n",
    "    # such that for each example, y is the vector of cues\n",
    "    # \n",
    "\n",
    "    # note to self: model uses sigmoid / softmax depending on whether I'm using binary crossentropy or categorical crossentropy\n",
    "    # in NEITHER CASE should it output negative results!\n",
    "    predictions = model.predict(\n",
    "        test_ds[0], # [email_titles, email_bodies]\n",
    "    )\n",
    "    # print(type(predictions)) # DEBUG\n",
    "    # print(np.asarray(predictions)) # DEBUG\n",
    "    # predictions = [0 if x < 0.5 else 1 for x in np.nditer(predictions)] # flattens before comparison\n",
    "    # predictions = np.asarray(predictions)\n",
    "    predictions = np.round(np.asarray(predictions)).astype(int)\n",
    "    # predictions = binary_thresholding(predictions)\n",
    "    # # test_labels = np.concatenate([y for x, y in test_ds], axis=0)\n",
    "    test_labels = test_ds[1] # y\n",
    "\n",
    "    # print(\"predicted labels: \", predictions) # DEBUG\n",
    "    # print(\"actual labels: \", test_labels) # DEBUG\n",
    "\n",
    "    # print(evaluation)\n",
    "    # conf_matrix = np.asarray(\n",
    "    #     tf.math.confusion_matrix(test_labels, predictions))\n",
    "\n",
    "    # print(\"confusion matrix:\")\n",
    "    # print(conf_matrix)\n",
    "\n",
    "    # conf_matrix_norm = np.asarray(\n",
    "    #     [conf_matrix[idx] / (np.sum(row) + 1e-7) for idx, row in enumerate(conf_matrix)])\n",
    "    # print('confusion matrix (percentage):')\n",
    "    # print(conf_matrix_norm)\n",
    "\n",
    "    # test accuracy per cues\n",
    "    right_labels_matrix = np.abs(np.abs(predictions - test_labels) - 1) # 0 if worng, 1 if right\n",
    "    # manual_accuracy = np.average(right_labels_matrix)\n",
    "    cues_accuracies = np.sum(right_labels_matrix, axis = 0) / len(right_labels_matrix)\n",
    "\n",
    "    # print accuracy of each cue\n",
    "    # print(\"cues accuracy: \", cues_accuracies) # DEBUG\n",
    "    # print(\"manual accuracy:\", manual_accuracy)\n",
    "    print(\"-- Accuracy of each Cue in Test DS --\")\n",
    "    for i in range(len(attributes)):\n",
    "        print(f'\\t{attributes[i]}: {cues_accuracies[i]}')\n",
    "\n",
    "    return (\n",
    "        evaluation[1], # accuracy\n",
    "        model\n",
    "    )\n",
    "\n",
    "# model training funcs + k-fold\n",
    "\n",
    "\n",
    "def pretrained_embedding(embedding):\n",
    "    # note: embedding is declared in the previous cell\n",
    "\n",
    "    vocab_size = len(embedding)\n",
    "    embedding_vector_size = len(embedding[embedding.index_to_key[0]])\n",
    "\n",
    "    # create embedding matrix\n",
    "    embedding_matrix = np.zeros((vocab_size, embedding_vector_size))\n",
    "    # iterate through embedding and copy word vectors as weights\n",
    "    for i in range(vocab_size):\n",
    "        embedding_matrix[i, :] = embedding[embedding.index_to_key[i]]\n",
    "\n",
    "    embedding_layer = layers.Embedding(\n",
    "        input_dim=vocab_size, output_dim=embedding_vector_size, trainable=False)\n",
    "    embedding_layer.build((None,))  # I have no idea why I should do this\n",
    "    # square brackets are because some layers take multiple types of weights\n",
    "    embedding_layer.set_weights([embedding_matrix])\n",
    "\n",
    "    return embedding_layer\n",
    "\n",
    "def binary_thresholding(element, threshold = 0.5):\n",
    "    return 1 if element >= threshold else 0\n",
    "\n",
    "# def kfold(ds, epochs, batch_size, k, BODY_LENgth, embedding):\n",
    "#     autotune = tf.data.AUTOTUNE\n",
    "\n",
    "#     if k == None:\n",
    "#         # normal stuff\n",
    "#         model = build_model(BODY_LENgth, embedding)\n",
    "\n",
    "#         train_ds, valid_ds, test_ds = train_valid_test_split(\n",
    "#             ds, 0.6, 0.2, batch_size)\n",
    "#         train_and_evaluate(\n",
    "#             model,\n",
    "#             train_ds=train_ds,\n",
    "#             valid_ds=valid_ds,\n",
    "#             test_ds=test_ds,\n",
    "#             epochs=epochs,\n",
    "#         )\n",
    "\n",
    "#     else:\n",
    "#         accuracies = []\n",
    "#         for i in range(k):\n",
    "#             print(f'fold {i}')\n",
    "\n",
    "#             model = build_model(BODY_LENgth, embedding)\n",
    "#             num_total = len(ds)\n",
    "#             num_test = np.floor(num_total / k)\n",
    "#             num_train = num_total - num_test\n",
    "\n",
    "#             test_range = [np.floor((i) * num_test),\n",
    "#                           np.floor((i + 1) * num_test)]\n",
    "#             train_ds_p1 = ds.take(test_range[0])\n",
    "#             train_ds_p2 = ds.skip(test_range[1])\n",
    "#             train_ds = train_ds_p1.concatenate(\n",
    "#                 train_ds_p2).batch(batch_size).prefetch(autotune)\n",
    "#             print(f'train dataset range: {test_range[0]} - {test_range[1]}')\n",
    "#             test_ds = ds.skip(\n",
    "#                 np.floor((i) * num_test)).take(num_test).batch(batch_size).prefetch(autotune)\n",
    "#             print(f'test dataset range: {test_range[0]} - {test_range[1]}')\n",
    "\n",
    "#             print(\n",
    "#                 f'train ds has {num_train} items in {len(train_ds)} batches.')\n",
    "#             print(f'test ds has {num_test} items in {len(test_ds)} batches.')\n",
    "\n",
    "#             accuracy = train_and_evaluate(\n",
    "#                 model,\n",
    "#                 train_ds,\n",
    "#                 test_ds,\n",
    "#                 epochs=epochs,\n",
    "#             )[0]\n",
    "\n",
    "#             print(\"accuracy: \", accuracy)\n",
    "#             accuracies.append(accuracy)\n",
    "\n",
    "#         print(f\"average accuracy: {np.average(accuracies)}\")\n",
    "\n",
    "# manually calculated accuracy: returns the accuracy of a batch\n",
    "# https://keras.io/api/metrics/\n",
    "# def vector_accuracy(y_true, y_pred):\n",
    "#     try:\n",
    "#         y_true[0]\n",
    "#     except:\n",
    "#         raise Exception(\"y_true should be subscriptable in vector_accuracy\")\n",
    "#     correctness_vector = np.abs(np.abs(y_true - y_pred) - 1)\n",
    "#     return np.average(correctness_vector)\n",
    "\n",
    "# gpu-fied vector_accuracy\n",
    "def vector_accuracy(y_true, y_pred):\n",
    "    try:\n",
    "        y_true[0]\n",
    "    except:\n",
    "        raise Exception(\"Y_true should be subscriptable\")\n",
    "    \n",
    "    y_pred = tf.round(y_pred)\n",
    "    correctness_vector = tf.abs(tf.abs(y_true - y_pred) - 1)\n",
    "    return tf.math.reduce_mean(correctness_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Email_ID</th>\n",
       "      <th>Sender</th>\n",
       "      <th>Subject</th>\n",
       "      <th>Email</th>\n",
       "      <th>Email_type</th>\n",
       "      <th>sender_mismatch</th>\n",
       "      <th>request_credentials</th>\n",
       "      <th>subject_suspicious</th>\n",
       "      <th>urgent</th>\n",
       "      <th>offer</th>\n",
       "      <th>Link_Mismatch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>235</td>\n",
       "      <td>no_reply@snapchat.com</td>\n",
       "      <td>Snapchat Login on February 15, 2019</td>\n",
       "      <td>&lt;h3&gt;Just logged in! &lt;/h3&gt;&lt;br&gt;Hi Nancy95,&lt;p&gt;It ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>236</td>\n",
       "      <td>security_awareness@secarmour.com</td>\n",
       "      <td>January Meeting: 2019</td>\n",
       "      <td>Hi Olivia,&lt;br&gt;&lt;h3 align=\"center\"&gt;Deep Dive: 20...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>237</td>\n",
       "      <td>no-reply@yahoo.com</td>\n",
       "      <td>Password change for your Yahoo account</td>\n",
       "      <td>Hi Ethan,&lt;br&gt;&lt;br&gt;The password for your Yahoo a...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>238</td>\n",
       "      <td>communications@em.aetna.com</td>\n",
       "      <td>Protect your health records on your Aetna memb...</td>\n",
       "      <td>&lt;h2 align=\"center\"&gt;Protecting your personal in...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>239</td>\n",
       "      <td>no-reply@dropboxmail.com</td>\n",
       "      <td>jacab invited you to check out Dropbox</td>\n",
       "      <td>Hi there,&lt;br&gt;&lt;p&gt;Jacob (jacob14@gmail.com) thin...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Email_ID                            Sender  \\\n",
       "234       235             no_reply@snapchat.com   \n",
       "235       236  security_awareness@secarmour.com   \n",
       "236       237                no-reply@yahoo.com   \n",
       "237       238       communications@em.aetna.com   \n",
       "238       239          no-reply@dropboxmail.com   \n",
       "\n",
       "                                               Subject  \\\n",
       "234                Snapchat Login on February 15, 2019   \n",
       "235                              January Meeting: 2019   \n",
       "236             Password change for your Yahoo account   \n",
       "237  Protect your health records on your Aetna memb...   \n",
       "238             jacab invited you to check out Dropbox   \n",
       "\n",
       "                                                 Email  Email_type  \\\n",
       "234  <h3>Just logged in! </h3><br>Hi Nancy95,<p>It ...           0   \n",
       "235  Hi Olivia,<br><h3 align=\"center\">Deep Dive: 20...           0   \n",
       "236  Hi Ethan,<br><br>The password for your Yahoo a...           0   \n",
       "237  <h2 align=\"center\">Protecting your personal in...           0   \n",
       "238  Hi there,<br><p>Jacob (jacob14@gmail.com) thin...           0   \n",
       "\n",
       "     sender_mismatch  request_credentials  subject_suspicious  urgent  offer  \\\n",
       "234                0                    0                   0       1      0   \n",
       "235                0                    0                   0       0      0   \n",
       "236                0                    0                   0       0      0   \n",
       "237                0                    0                   0       0      0   \n",
       "238                0                    0                   0       0      0   \n",
       "\n",
       "     Link_Mismatch  \n",
       "234              0  \n",
       "235              0  \n",
       "236              0  \n",
       "237              0  \n",
       "238              0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([1, 0])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average title length: 4.815899581589958\n"
     ]
    }
   ],
   "source": [
    "# import dataset\n",
    "df = pd.read_csv('../data/Emails_With_Cues.csv', encoding = \"windows-1254\")\n",
    "df = df.rename(columns = {'subject_suspecious': 'subject_suspicious'})\n",
    "df = df.replace(['Phishing', 'phishing', 'Ham', 'ham', 'Attention_check'], [1, 1, 0, 0, -1])\n",
    "df = df[df['Email_type'] != -1]\n",
    "display(df.tail())\n",
    "display(df['Email_type'].unique())\n",
    "print(\"average title length:\", np.average([len(x.split()) for x in df['Subject']]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 0, 1, 1, 0, 1],\n",
       "       [1, 1, 0, 0, 0, 1, 1],\n",
       "       [1, 1, 1, 1, 1, 0, 1],\n",
       "       [1, 1, 0, 0, 0, 1, 1],\n",
       "       [1, 0, 1, 0, 0, 1, 0],\n",
       "       [1, 0, 1, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 1, 0, 0],\n",
       "       [0, 0, 0, 1, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# sender mismatch is basically impersonation (micr0soft)\n",
    "df_test = df[180 : 190]\n",
    "attributes = ['Email_type', 'sender_mismatch', 'request_credentials', 'subject_suspicious', 'urgent', 'offer', 'Link_Mismatch']\n",
    "test_numpy_input = dataset_to_numpy(df_test, attributes)\n",
    "display(test_numpy_input)\n",
    "\n",
    "# test_numpy_input = np.insert([3], )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed text #0: []\n",
      "---------------------------\n",
      "tokenizing...\n",
      "padding sequences...\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "feature vector shape: (239, 8)\n",
      "Processed text #0: ['*', '*', '*', '*', '*', '*', '*', '*', '*', 'please', 'respond', 'email', '*', '*', '*', '*', '*', '*', '*', '*', '*', 'record', 'show', 'entered', 'win', 'state', 'powerball', 'jackpot', 'num', '/', 'num', '/', 'num', '.', 'receiving', 'email', 'listed', 'one', 'winner', '.', 'claim', 'prize', 'please', 'visit', 'site', 'fill', 'information', 'needed', 'collect', '.', 'must', 'process', 'information', 'within', 'week', 'time', 'may', 'lose', 'winning', '.', 'congratulation', '!', 'collect', 'earnings', '!', 'please', 'click', 'prompt', 'response', 'regarding', 'matter', 'appreciated', '.', 'sincerely', ',', 'powerball', 'team']\n",
      "---------------------------\n",
      "tokenizing...\n",
      "padding sequences...\n",
      "[[   42    42    42 ...     0     0     0]\n",
      " [   42    42    42 ...     0     0     0]\n",
      " [  996     4  3145 ...     0     0     0]\n",
      " ...\n",
      " [  589 31134     4 ...     0     0     0]\n",
      " [ 3709     1   416 ...  2471  2311     1]\n",
      " [  589     4 11532 ...     0     0     0]]\n",
      "feature vector shape: (239, 80)\n",
      "original data:\n",
      "<<0>> <p><strong>17/10/2017<br />Account No: 108-455294-800125-MN</strong></p><p>&nbsp;</p><p>To our valued <em>Walmart</em> customer,&nbsp;</p><p>&nbsp;</p><p>The team at <em>Walmart Online Services</em> is happy to announce that you have been chosen as the &#39;User of the month&#39; lottery&nbsp;winner!&nbsp;This is a monthly event where we randomly choose a customer to receive&nbsp;free Walmart coupons. In order to&nbsp;access your coupons, please visit the link below:</p><p>&nbsp;</p><p><strong><a href=\"http://walmart/rewards/coupons\" onclick=\"return false;\">Walmart Reward Coupons</a></strong></p><p>&nbsp;</p><p>Using any of these coupons will result in a donation to St. Jude&#39;s Children Hospital, so you can now receive free items and donate to a good cause at the same time. We hope you&#39;ll help support us!<br /><br /><em><strong>From,</strong></em></p><p><strong>Your Friends at Walmart Online Services</strong></p><p>&nbsp;</p>\n",
      "<<1>> <p>What would&nbsp;you do with extra money each month? &nbsp;</p><p>&nbsp;</p><p>JP Morgan&nbsp;is offering a new 30 Year Fixed Term Loan with rates starting from <em><strong>1.05%</strong></em> to qualified customers. Its easy to see if you qualify! Don&#39;t let this opportunity pass you by!</p><p>&nbsp;</p><p>To see if you qualify, please click the link below.</p><p>&nbsp;</p><p><a target=\"\" href=\"http://Chase-Security.html\" onclick=\"return false;\">https://chaseonline.com/promotional/30YearJumbo/qualification.aspx</a>&nbsp;</p><p>&nbsp;</p><p>We look forward to hearing from&nbsp;you,&nbsp;</p><p>&nbsp;</p><p>Sincerely,&nbsp;</p><p>JP Morgan Chase Bank, N.A.</p>\n",
      "<<2>> <p>Dear Loyal Customer:</p><p>&nbsp;</p><p>JP Morgan Chase Bank is excited to announce their&nbsp;30 Year Fixed Term Jumbo Loan with rates starting from 1.05% to qualified customers to refinance or get a loan for a house</p><p>&nbsp;</p><p>In only seconds you can see if you qualify, just click here. We have representives standing by.&nbsp;</p><p>&nbsp;</p><p><a target=\"\" href=\"http://Chase-Security.html\" onclick=\"return false;\">https://chaseonline.com/promotional/30YearJumbo/qualification.aspx</a>&nbsp;</p><p>&nbsp;</p><p>We look forward to serving all of your financial needs.&nbsp;</p><p>&nbsp;</p><p>Sincerely,&nbsp;</p><p>JP Morgan Chase Bank, N.A.</p><p>Chase Privacy Operations, P.O. Box 659752, San Antonio, TX 78265-9752.&nbsp;</p><p>&copy; 2016 JPMorgan Chase &amp; Co.</p>\n",
      "<<3>> <p>Dear Sir or Madam:</p><p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; We are required by law to contact you with the following information. You account is in need of prompt attention. With one click you will be able to update your account&nbsp;and continue using our simple, no risk website to continue with all your business needs. We encourage you to do this as quickly as possible. Without further action on your part, we will find it necessary to close this account.</p><p><a href=\"http://www.USSAgoogle.com\" onclick=\"return false;\">&nbsp;Please click this sentence</a></p><p>&nbsp;</p><p>Thank you for banking with us.</p><p>&nbsp;</p><p>Sincerely,</p><p>USAA Bank</p>\n",
      "<<4>> <p>To Whom It May Concern:</p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; I possess a Master&#39;s Degree in Accounting, and am currently in the process of completing my CPA qualifications. I also have advanced experience&nbsp;in Microsoft Access, Excel, Word and Powerpoint, QuickBooks, and other accounting software. I believe that I could be a major asset to your company.</p><p>&nbsp;</p><p>Please take the time to look through my qualifications:</p><p><a target=\"_blank\" href=\"https://gmail.com/myemail\" onclick=\"return false;\">My CV</a></p><p>&nbsp;</p><p>I thank you for your time and hope that you will consider me for a position.</p><p>&nbsp;</p><p>Best,</p><p>Ryan Walters</p>\n",
      "<<5>> <p>&nbsp;</p><p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; I am having some serious medical issues and could use your help cousin :(. Please donate to me on the page below and give me a call when I&#39;m all better.&nbsp;</p><p><a href=\"http://www.dfnbk.com\" onclick=\"return false;\">Link!</a></p>\n",
      "<<6>> <p>Hello,</p><p>&nbsp;</p><p>Thank you for shopping with us.</p><p>We will email you once your item&nbsp;has shipped.</p><p>&nbsp;</p><p>Order Details:</p><p>Order # 002-527657-2343090</p><p>Shipping: FREE Two-Day Shipping</p><p>Order total: $109.29</p><p>&nbsp;</p><p>If you didn&rsquo;t authorize the transaction, please <a href=\"http://www.refund.item\" onclick=\"return false;\" > Click Here </a>to receive a full refund.</p><p>&nbsp;</p><p>We hope to see you again soon.</p><p>&nbsp;</p><p>Amazon.com</p>\n",
      "<<7>> <p>&nbsp;</p><p>&nbsp;</p><p>We are writing to you because your federal Tax refund&nbsp;is now ready to be sent. To confirm your account please visit the website below.&nbsp;</p><p>If verification is not&nbsp;made within the next 72 hours your refund could substantially be delayed. Log in now to secure your refund.&nbsp;</p><p>&nbsp;</p><p>&nbsp;<a href=\"http://www.IR5.com\" onclick=\"return false;\">www.irs.com</a> &nbsp;</p><p>&nbsp;</p><p>Again, please respond within the next 72 hours to avoid delays to your refund.</p><p>&nbsp;</p><p>Sincerely,</p><p>&nbsp;</p><p>IRS Refund Department</p>\n",
      "<<8>> <p><strong>Your Account has been locked! You can resolve this now.</strong>&nbsp;</p><p>&nbsp;</p><p>Case id : 9000321-128. Login attempt from unknown device.&nbsp;</p><p>&nbsp;</p><p><strong>Dear Client&nbsp;</strong></p><p>Someone has accessed your account, so we have temporarily locked it to keep your personal informations in safe. To unlock your account, you may need to pass a security check. Note that attempting to access someone else is a violation of PayPals terms. It may also be illegal. To reset your account:&nbsp;</p><p>1-Click on the link <a target=\"\" href=\"PayPal1-Security.html\" onclick=\"return false;\">PayPal-Security.html</a>.&nbsp;</p><p>2-Open the page in a browser window secure.&nbsp;</p><p>3-Follow the instructions.</p><p>&nbsp;</p><p>&nbsp;</p>\n",
      "<<9>> <h4>Add a backup phone as an alternative 2-step Verification step</h4>andrew19@gmail.com<br><br>A backup phone number ensures that you can sign in when your main second verification step is unavailable.<br><br>Add a backup number and see other personalised recommendations in the Security Check-up.<h4><a href=\"https://www.gmail.com\" onclick=\"return false;\">TAKE ACTION </a></h4>\n",
      "------------------------------------------\n",
      "split input: \n",
      "<<0>> ['num', '/', 'num', '/', 'num', 'account', ':', 'num', '-', 'num', '-', 'num', '-', 'mn', 'valued', 'walmart', 'customer', ',', 'team', 'walmart', 'online', 'service', 'happy', 'announce', 'chosen', 'user', 'month', 'lottery', 'winner', '!', 'monthly', 'event', 'randomly', 'choose', 'customer', 'receive', 'free', 'walmart', 'coupon', '.', 'order', 'access', 'coupon', ',', 'please', 'visit', 'link', ':', 'walmart', 'reward', 'coupon', 'using', 'coupon', 'result', 'donation', 'st', '.', 'jude', 'child', 'hospital', ',', 'receive', 'free', 'item', 'donate', 'good', 'cause', 'time', '.', 'hope', 'help', 'support', 'u', '!', ',', 'friend', 'walmart', 'online', 'service', '<user>']\n",
      "<<1>> ['would', 'extra', 'money', 'month', '?', 'jp', 'morgan', 'offering', 'new', 'num', 'year', 'fixed', 'term', 'loan', 'rate', 'starting', 'num', '.', 'num', '%', 'qualified', 'customer', '.', 'easy', 'see', 'qualify', '!', 'let', 'opportunity', 'pas', '!', 'see', 'qualify', ',', 'please', 'click', 'link', '.', 'url', 'look', 'forward', 'hearing', ',', 'sincerely', ',', 'jp', 'morgan', 'chase', 'bank', ',', 'n', '.', '.', '<user>', '<user>', '<user>', '<user>', '<user>', '<user>', '<user>', '<user>', '<user>', '<user>', '<user>', '<user>', '<user>', '<user>', '<user>', '<user>', '<user>', '<user>', '<user>', '<user>', '<user>', '<user>', '<user>', '<user>', '<user>', '<user>', '<user>']\n",
      "<<2>> ['dear', 'loyal', 'customer', ':', 'jp', 'morgan', 'chase', 'bank', 'excited', 'announce', 'num', 'year', 'fixed', 'term', 'jumbo', 'loan', 'rate', 'starting', 'num', '.', 'num', '%', 'qualified', 'customer', 'refinance', 'get', 'loan', 'house', 'second', 'see', 'qualify', ',', 'click', '.', 'ﾟﾟﾟｵﾔｽﾐｰ', 'standing', '.', 'url', 'look', 'forward', 'serving', 'financial', 'need', '.', 'sincerely', ',', 'jp', 'morgan', 'chase', 'bank', ',', 'n', '.', '.', 'chase', 'privacy', 'operation', ',', 'p', '.', '.', 'box', 'num', ',', 'san', 'antonio', ',', 'tx', 'num', '-', 'num', '.', 'num', 'jpmorgan', 'chase', 'co', '.', '<user>', '<user>', '<user>']\n",
      "<<3>> ['dear', 'sir', 'madam', ':', 'required', 'law', 'contact', 'following', 'information', '.', 'account', 'need', 'prompt', 'attention', '.', 'one', 'click', 'able', 'update', 'account', 'continue', 'using', 'simple', ',', 'risk', 'website', 'continue', 'business', 'need', '.', 'encourage', 'quickly', 'possible', '.', 'without', 'action', 'part', ',', 'find', 'necessary', 'close', 'account', '.', 'please', 'click', 'sentence', 'thank', 'banking', 'u', '.', 'sincerely', ',', 'usaa', 'bank', '<user>', '<user>', '<user>', '<user>', '<user>', '<user>', '<user>', '<user>', '<user>', '<user>', '<user>', '<user>', '<user>', '<user>', '<user>', '<user>', '<user>', '<user>', '<user>', '<user>', '<user>', '<user>', '<user>', '<user>', '<user>', '<user>']\n",
      "<<4>> ['may', 'concern', ':', 'posse', 'master', 'degree', 'accounting', ',', 'currently', 'process', 'completing', 'cpa', 'qualification', '.', 'also', 'advanced', 'experience', 'microsoft', 'access', ',', 'excel', ',', 'word', 'powerpoint', ',', 'quickbooks', ',', 'accounting', 'software', '.', 'believe', 'could', 'major', 'asset', 'company', '.', 'please', 'take', 'time', 'look', 'qualification', ':', 'cv', 'thank', 'time', 'hope', 'consider', 'position', '.', 'best', ',', 'ryan', 'walter', '<user>', '<user>', '<user>', '<user>', '<user>', '<user>', '<user>', '<user>', '<user>', '<user>', '<user>', '<user>', '<user>', '<user>', '<user>', '<user>', '<user>', '<user>', '<user>', '<user>', '<user>', '<user>', '<user>', '<user>', '<user>', '<user>', '<user>']\n",
      "<<5>> ['serious', 'medical', 'issue', 'could', 'use', 'help', 'cousin', ':', '(', '.', 'please', 'donate', 'page', 'give', 'call', 'better', '.', 'link', '!', '<user>', '<user>', '<user>', '<user>', '<user>', '<user>', '<user>', '<user>', '<user>', '<user>', '<user>', '<user>', '<user>', '<user>', '<user>', '<user>', '<user>', '<user>', '<user>', '<user>', '<user>', '<user>', '<user>', '<user>', '<user>', '<user>', '<user>', '<user>', '<user>', '<user>', '<user>', '<user>', '<user>', '<user>', '<user>', '<user>', '<user>', '<user>', '<user>', '<user>', '<user>', '<user>', '<user>', '<user>', '<user>', '<user>', '<user>', '<user>', '<user>', '<user>', '<user>', '<user>', '<user>', '<user>', '<user>', '<user>', '<user>', '<user>', '<user>', '<user>', '<user>']\n",
      "<<6>> ['hello', ',', 'thank', 'shopping', 'u', '.', 'email', 'item', 'shipped', '.', 'order', 'detail', ':', 'order', 'num', '-', 'num', '-', 'num', 'shipping', ':', 'free', 'two', '-', 'day', 'shipping', 'order', 'total', ':', '$', 'num', '.', 'num', 'authorize', 'transaction', ',', 'please', 'click', 'receive', 'full', 'refund', '.', 'hope', 'see', 'soon', '.', 'url', '<user>', '<user>', '<user>', '<user>', '<user>', '<user>', '<user>', '<user>', '<user>', '<user>', '<user>', '<user>', '<user>', '<user>', '<user>', '<user>', '<user>', '<user>', '<user>', '<user>', '<user>', '<user>', '<user>', '<user>', '<user>', '<user>', '<user>', '<user>', '<user>', '<user>', '<user>', '<user>', '<user>']\n",
      "<<7>> ['writing', 'federal', 'tax', 'refund', 'ready', 'sent', '.', 'confirm', 'account', 'please', 'visit', 'website', '.', 'verification', 'made', 'within', 'next', 'num', 'hour', 'refund', 'could', 'substantially', 'delayed', '.', 'log', 'secure', 'refund', '.', 'url', ',', 'please', 'respond', 'within', 'next', 'num', 'hour', 'avoid', 'delay', 'refund', '.', 'sincerely', ',', 'irs', 'refund', 'department', '<user>', '<user>', '<user>', '<user>', '<user>', '<user>', '<user>', '<user>', '<user>', '<user>', '<user>', '<user>', '<user>', '<user>', '<user>', '<user>', '<user>', '<user>', '<user>', '<user>', '<user>', '<user>', '<user>', '<user>', '<user>', '<user>', '<user>', '<user>', '<user>', '<user>', '<user>', '<user>', '<user>', '<user>', '<user>']\n",
      "<<8>> ['account', 'locked', '!', 'resolve', '.', 'case', 'id', ':', 'num', '-', 'num', '.', 'login', 'attempt', 'unknown', 'device', '.', 'dear', 'client', 'someone', 'accessed', 'account', ',', 'temporarily', 'locked', 'keep', 'personal', 'information', 'safe', '.', 'unlock', 'account', ',', 'may', 'need', 'pas', 'security', 'check', '.', 'note', 'attempting', 'access', 'someone', 'else', 'violation', 'ﾟﾟﾟｵﾔｽﾐｰ', 'term', '.', 'may', 'also', 'illegal', '.', 'reset', 'account', ':', 'num', '-', 'click', 'link', 'url', '.', 'num', '-', 'open', 'page', 'browser', 'window', 'secure', '.', 'num', '-', 'follow', 'instruction', '.', '<user>', '<user>', '<user>', '<user>', '<user>', '<user>']\n",
      "<<9>> ['add', 'backup', 'phone', 'alternative', 'num', '-', 'step', 'verification', 'step', 'url', 'backup', 'phone', 'number', 'ensures', 'sign', 'main', 'second', 'verification', 'step', 'unavailable', '.', 'add', 'backup', 'number', 'see', 'personalised', 'recommendation', 'security', 'check', '-', '.', 'take', 'action', '<user>', '<user>', '<user>', '<user>', '<user>', '<user>', '<user>', '<user>', '<user>', '<user>', '<user>', '<user>', '<user>', '<user>', '<user>', '<user>', '<user>', '<user>', '<user>', '<user>', '<user>', '<user>', '<user>', '<user>', '<user>', '<user>', '<user>', '<user>', '<user>', '<user>', '<user>', '<user>', '<user>', '<user>', '<user>', '<user>', '<user>', '<user>', '<user>', '<user>', '<user>', '<user>', '<user>', '<user>', '<user>', '<user>', '<user>']\n",
      "------------------------------------------\n",
      "tokenized input: \n",
      "<<0>> [3709, 38, 3709, 38, 3709, 1548, 2, 3709, 28, 3709, 28, 3709, 28, 2886, 54234, 7214, 7922, 4, 302, 7214, 949, 2465, 177, 8261, 12628, 3920, 1423, 16634, 3104, 9, 21024, 2466, 8209, 2665, 7922, 6398, 424, 7214, 12285, 1, 1853, 7530, 12285, 4, 200, 1621, 1345, 2, 7214, 15037, 12285, 1802, 12285, 5678, 23473, 993, 1, 24751, 1916, 2974, 4, 6398, 424, 6657, 8223, 117, 507, 135, 1, 420, 515, 1215, 51, 9, 4, 531, 7214, 949, 2465, 0]\n",
      "<<1>> [196, 2052, 580, 1423, 14, 9182, 6711, 13830, 122, 3709, 356, 8090, 6261, 9621, 3760, 1752, 3709, 1, 3709, 299, 28111, 7922, 1, 1227, 163, 30517, 9, 265, 5571, 354, 9, 163, 30517, 4, 200, 2215, 1345, 1, 14119, 273, 1732, 3856, 4, 11404, 4, 9182, 6711, 5037, 2699, 4, 36, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "<<2>> [1034, 3972, 7922, 2, 9182, 6711, 5037, 2699, 870, 8261, 3709, 356, 8090, 6261, 28257, 9621, 3760, 1752, 3709, 1, 3709, 299, 28111, 7922, 158204, 87, 9621, 543, 1296, 163, 30517, 4, 2215, 1, 1193513, 4454, 1, 14119, 273, 1732, 15269, 8617, 171, 1, 11404, 4, 9182, 6711, 5037, 2699, 4, 36, 1, 1, 5037, 13958, 13787, 4, 351, 1, 1, 2271, 3709, 4, 1401, 6683, 4, 7612, 3709, 28, 3709, 1, 3709, 98039, 5037, 2384, 1, 0, 0, 0]\n",
      "<<3>> [1034, 2621, 24102, 2, 13544, 3187, 3514, 927, 5386, 1, 1548, 171, 62081, 1823, 1, 96, 2215, 1773, 1880, 1548, 3475, 1802, 1617, 4, 5889, 2529, 3475, 1249, 171, 1, 19253, 5935, 2436, 1, 663, 3196, 802, 4, 470, 10008, 1213, 1548, 1, 200, 2215, 8363, 337, 24686, 51, 1, 11404, 4, 276017, 2699, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "<<4>> [530, 14730, 2, 47592, 4333, 9310, 21018, 4, 3996, 7014, 51524, 38391, 78372, 1, 894, 16857, 3084, 6506, 7530, 4, 24064, 4, 892, 33943, 4, 178673, 4, 21018, 7287, 1, 552, 297, 3577, 39541, 3054, 1, 200, 284, 135, 273, 78372, 2, 9027, 337, 135, 420, 6213, 5956, 1, 209, 4, 2827, 16956, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "<<5>> [1507, 7294, 4649, 297, 716, 515, 2569, 2, 17, 1, 200, 8223, 1737, 374, 462, 295, 1, 1345, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "<<6>> [996, 4, 337, 1652, 51, 1, 2600, 6657, 27955, 1, 1853, 13794, 2, 1853, 3709, 28, 3709, 28, 3709, 7723, 2, 424, 568, 28, 125, 7723, 1853, 2413, 2, 206, 3709, 1, 3709, 284862, 80102, 4, 200, 2215, 6398, 833, 31845, 1, 420, 163, 698, 1, 14119, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "<<7>> [3145, 8677, 5098, 31845, 579, 2089, 1, 9255, 1548, 200, 1621, 2529, 1, 80719, 425, 4615, 411, 3709, 1194, 31845, 297, 239791, 18502, 1, 8253, 17559, 31845, 1, 14119, 4, 200, 7093, 4615, 411, 3709, 1194, 5839, 9023, 31845, 1, 11404, 4, 21039, 31845, 13272, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "<<8>> [1548, 7054, 9, 18309, 1, 1815, 2471, 2, 3709, 28, 3709, 1, 25037, 7990, 9697, 13249, 1, 1034, 13322, 238, 264007, 1548, 4, 30878, 7054, 416, 2615, 5386, 2184, 1, 17527, 1548, 4, 530, 171, 354, 4739, 525, 1, 2586, 22676, 7530, 238, 645, 49497, 1193513, 6261, 1, 530, 894, 7188, 1, 24401, 1548, 2, 3709, 28, 2215, 1345, 14119, 1, 3709, 28, 784, 1737, 24107, 3962, 17559, 1, 3709, 28, 84, 58103, 1, 0, 0, 0, 0, 0, 0]\n",
      "<<9>> [1894, 16464, 448, 15792, 3709, 28, 2022, 80719, 2022, 14119, 16464, 448, 1077, 148726, 1793, 1029, 1296, 80719, 2022, 60682, 1, 1894, 16464, 1077, 163, 67974, 51557, 4739, 525, 28, 1, 284, 3196, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "------------------------------------------\n",
      "labels:  [[1 0 0 0 0 1 1]\n",
      " [1 1 0 0 0 1 1]\n",
      " [1 1 0 0 0 1 1]\n",
      " [1 0 1 0 1 0 1]\n",
      " [1 0 0 0 0 0 1]\n",
      " [1 0 1 0 1 0 1]\n",
      " [1 0 0 0 0 0 1]\n",
      " [1 1 1 0 1 0 1]\n",
      " [1 0 1 1 1 0 1]\n",
      " [0 0 0 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "# preprocessing\n",
    "\n",
    "# tokenize + the usual stuff\n",
    "# embedding = gdownload.load('glove-wiki-gigaword-100') # pretrained embedding --> much cleaner than twitter stuff\n",
    "# embedding = gdownload.load('glove-twitter-200') # pretrained embedding \n",
    "embedding = gdownload.load('glove-twitter-50') # pretrained embedding \n",
    "# embedding = gdownload.load('word2vec-google-news-300')\n",
    "original_texts = np.asarray(df['Email']) # I'll use this to check the preprocessing process\n",
    "\n",
    "# Xs\n",
    "# email_senders = # too complex\n",
    "SUBJECT_LEN = 8\n",
    "BODY_LEN = 80\n",
    "email_titles = preprocess_txt_list(df['Email_ID'], embedding, BODY_LENgth = SUBJECT_LEN) # titles are shorter\n",
    "email_bodies = preprocess_txt_list(df['Email'], embedding, BODY_LENgth = BODY_LEN)\n",
    "\n",
    "# Ys\n",
    "# email_types = preprocess_annotations(df['Email_type']) # embedded in email_cues\n",
    "email_types = dataset_to_numpy(df, ['Email_type', 'sender_mismatch', 'request_credentials', 'subject_suspicious', 'urgent', 'offer', 'Link_Mismatch'])\n",
    "NUM_FACTORS = len(test_numpy_input[0])\n",
    "# print(NUM_FACTORS)\n",
    "\n",
    "# shuffle the data\n",
    "\n",
    "###### vvvv SEED IS HERE vvvv ######\n",
    "# seed = 183\n",
    "# seed = 89\n",
    "# seed = 11\n",
    "# seed = 42\n",
    "seed = 30\n",
    "###### ^^^^ SEED IS HERE ^^^^ ######\n",
    "\n",
    "original_texts = shuffle(original_texts, random_state = seed) # debug\n",
    "email_bodies = shuffle(email_bodies, random_state = seed)\n",
    "email_types = shuffle(email_types, random_state = seed)\n",
    "# type_labels = shuffle(type_labels)\n",
    "\n",
    "# reduce data for faster training # REMOVE LATER\n",
    "ratio_keep = 1 # IXME: revert to 1 after prototyping\n",
    "original_texts = original_texts[:int(len(original_texts) * ratio_keep)] # debug\n",
    "email_titles = email_titles[:int(len(email_titles) * ratio_keep)]\n",
    "email_bodies = email_bodies[:int(len(email_bodies) * ratio_keep)]\n",
    "email_types = email_types[:int(len(email_types) * ratio_keep)]\n",
    "# type_labels = type_labels[:int(len(type_labels) * ratio_keep)]\n",
    "\n",
    "# DEBUG\n",
    "def print_list(title, list):\n",
    "    print(title)\n",
    "    for i, x in enumerate(list):\n",
    "        print(f'<<{i}>>', x)\n",
    "    print(\"------------------------------------------\")\n",
    "\n",
    "sample_length = 10\n",
    "print_list(\"original data:\", original_texts[:sample_length])\n",
    "tokenized_input_sample = [[index for index in x] for x in email_bodies][:sample_length]\n",
    "print_list(\"split input: \", [[embedding.index_to_key[index] for index in example] for example in tokenized_input_sample])\n",
    "print_list(\"tokenized input: \", tokenized_input_sample)\n",
    "print(\"labels: \", email_types[:sample_length])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train ds has 191 items.\n",
      "valid ds has 23 items.\n",
      "test ds has 25 items.\n",
      "Model: \"model_9\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_20 (InputLayer)       [(None, 80)]                 0         []                            \n",
      "                                                                                                  \n",
      " token_and_position_embeddi  (None, 80, 50)               5967970   ['input_20[0][0]']            \n",
      " ng_9 (TokenAndPositionEmbe                               0                                       \n",
      " dding)                                                                                           \n",
      "                                                                                                  \n",
      " transformer_encoder_40 (Tr  (None, 80, 50)               1302732   ['token_and_position_embedding\n",
      " ansformerEncoder)                                                  _9[0][0]']                    \n",
      "                                                                                                  \n",
      " transformer_encoder_41 (Tr  (None, 80, 50)               1302732   ['transformer_encoder_40[0][0]\n",
      " ansformerEncoder)                                                  ']                            \n",
      "                                                                                                  \n",
      " transformer_encoder_42 (Tr  (None, 80, 50)               1302732   ['transformer_encoder_41[0][0]\n",
      " ansformerEncoder)                                                  ']                            \n",
      "                                                                                                  \n",
      " transformer_encoder_43 (Tr  (None, 80, 50)               1302732   ['transformer_encoder_42[0][0]\n",
      " ansformerEncoder)                                                  ']                            \n",
      "                                                                                                  \n",
      " transformer_encoder_44 (Tr  (None, 80, 50)               1302732   ['transformer_encoder_43[0][0]\n",
      " ansformerEncoder)                                                  ']                            \n",
      "                                                                                                  \n",
      " transformer_encoder_45 (Tr  (None, 80, 50)               1302732   ['transformer_encoder_44[0][0]\n",
      " ansformerEncoder)                                                  ']                            \n",
      "                                                                                                  \n",
      " transformer_encoder_46 (Tr  (None, 80, 50)               1302732   ['transformer_encoder_45[0][0]\n",
      " ansformerEncoder)                                                  ']                            \n",
      "                                                                                                  \n",
      " transformer_encoder_47 (Tr  (None, 80, 50)               1302732   ['transformer_encoder_46[0][0]\n",
      " ansformerEncoder)                                                  ']                            \n",
      "                                                                                                  \n",
      " transformer_encoder_48 (Tr  (None, 80, 50)               1302732   ['transformer_encoder_47[0][0]\n",
      " ansformerEncoder)                                                  ']                            \n",
      "                                                                                                  \n",
      " transformer_encoder_49 (Tr  (None, 80, 50)               1302732   ['transformer_encoder_48[0][0]\n",
      " ansformerEncoder)                                                  ']                            \n",
      "                                                                                                  \n",
      " transformer_encoder_50 (Tr  (None, 80, 50)               1302732   ['transformer_encoder_49[0][0]\n",
      " ansformerEncoder)                                                  ']                            \n",
      "                                                                                                  \n",
      " transformer_encoder_51 (Tr  (None, 80, 50)               1302732   ['transformer_encoder_50[0][0]\n",
      " ansformerEncoder)                                                  ']                            \n",
      "                                                                                                  \n",
      " gru_19 (GRU)                (None, 8)                    1440      ['transformer_encoder_51[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " dense_141 (Dense)           (None, 32)                   288       ['gru_19[0][0]']              \n",
      "                                                                                                  \n",
      " input_19 (InputLayer)       [(None, 8)]                  0         []                            \n",
      "                                                                                                  \n",
      " dense_143 (Dense)           (None, 7)                    231       ['dense_141[0][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 75314443 (287.30 MB)\n",
      "Trainable params: 75314443 (287.30 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "6/6 [==============================] - 57s 987ms/step - loss: 0.6587 - auc: 0.6410 - prec: 0.5830 - rec: 0.6719 - vector_accuracy: 0.6112 - val_loss: 0.6014 - val_auc: 0.6980 - val_prec: 0.5942 - val_rec: 0.5395 - val_vector_accuracy: 0.6087\n",
      "Epoch 2/100\n",
      "6/6 [==============================] - 3s 439ms/step - loss: 0.6351 - auc: 0.6470 - prec: 0.6029 - rec: 0.6563 - vector_accuracy: 0.6268 - val_loss: 0.5960 - val_auc: 0.7045 - val_prec: 0.6522 - val_rec: 0.7895 - val_vector_accuracy: 0.7019\n",
      "Epoch 3/100\n",
      "6/6 [==============================] - 3s 441ms/step - loss: 0.6287 - auc: 0.6547 - prec: 0.7187 - rec: 0.4728 - vector_accuracy: 0.6573 - val_loss: 0.6051 - val_auc: 0.6923 - val_prec: 0.7826 - val_rec: 0.4737 - val_vector_accuracy: 0.6894\n",
      "Epoch 4/100\n",
      "6/6 [==============================] - 3s 433ms/step - loss: 0.6260 - auc: 0.6662 - prec: 0.6894 - rec: 0.5350 - vector_accuracy: 0.6603 - val_loss: 0.6015 - val_auc: 0.7045 - val_prec: 0.6232 - val_rec: 0.5658 - val_vector_accuracy: 0.6335\n",
      "Epoch 5/100\n",
      "6/6 [==============================] - 2s 405ms/step - loss: 0.6251 - auc: 0.6674 - prec: 0.6933 - rec: 0.5272 - vector_accuracy: 0.6604 - val_loss: 0.6069 - val_auc: 0.7045 - val_prec: 0.7826 - val_rec: 0.4737 - val_vector_accuracy: 0.6894\n",
      "Epoch 6/100\n",
      "6/6 [==============================] - 3s 428ms/step - loss: 0.6254 - auc: 0.6686 - prec: 0.7408 - rec: 0.4401 - vector_accuracy: 0.6566 - val_loss: 0.6049 - val_auc: 0.7045 - val_prec: 0.7826 - val_rec: 0.4737 - val_vector_accuracy: 0.6894\n",
      "Epoch 7/100\n",
      "6/6 [==============================] - 2s 417ms/step - loss: 0.6248 - auc: 0.6778 - prec: 0.7250 - rec: 0.4510 - vector_accuracy: 0.6535 - val_loss: 0.6022 - val_auc: 0.7045 - val_prec: 0.6232 - val_rec: 0.5658 - val_vector_accuracy: 0.6335\n",
      "Epoch 8/100\n",
      "6/6 [==============================] - 3s 445ms/step - loss: 0.6263 - auc: 0.6717 - prec: 0.6564 - rec: 0.5645 - vector_accuracy: 0.6485 - val_loss: 0.6027 - val_auc: 0.7045 - val_prec: 0.7826 - val_rec: 0.4737 - val_vector_accuracy: 0.6894\n",
      "Epoch 9/100\n",
      "6/6 [==============================] - 3s 447ms/step - loss: 0.6259 - auc: 0.6744 - prec: 0.7408 - rec: 0.4401 - vector_accuracy: 0.6564 - val_loss: 0.6082 - val_auc: 0.6782 - val_prec: 0.7826 - val_rec: 0.4737 - val_vector_accuracy: 0.6894\n",
      "Epoch 10/100\n",
      "6/6 [==============================] - 3s 432ms/step - loss: 0.6265 - auc: 0.6718 - prec: 0.7408 - rec: 0.4401 - vector_accuracy: 0.6567 - val_loss: 0.6064 - val_auc: 0.7045 - val_prec: 0.7826 - val_rec: 0.4737 - val_vector_accuracy: 0.6894\n",
      "Epoch 11/100\n",
      "6/6 [==============================] - 2s 416ms/step - loss: 0.6249 - auc: 0.6712 - prec: 0.6937 - rec: 0.4930 - vector_accuracy: 0.6514 - val_loss: 0.6030 - val_auc: 0.7045 - val_prec: 0.6232 - val_rec: 0.5658 - val_vector_accuracy: 0.6335\n",
      "Epoch 12/100\n",
      "6/6 [==============================] - 2s 400ms/step - loss: 0.6249 - auc: 0.6686 - prec: 0.6979 - rec: 0.4743 - vector_accuracy: 0.6485 - val_loss: 0.6024 - val_auc: 0.7045 - val_prec: 0.7826 - val_rec: 0.4737 - val_vector_accuracy: 0.6894\n",
      "Epoch 13/100\n",
      "6/6 [==============================] - 2s 429ms/step - loss: 0.6247 - auc: 0.6741 - prec: 0.7408 - rec: 0.4401 - vector_accuracy: 0.6565 - val_loss: 0.6016 - val_auc: 0.7045 - val_prec: 0.7826 - val_rec: 0.4737 - val_vector_accuracy: 0.6894\n",
      "Epoch 14/100\n",
      "6/6 [==============================] - 3s 427ms/step - loss: 0.6245 - auc: 0.6682 - prec: 0.7396 - rec: 0.4417 - vector_accuracy: 0.6565 - val_loss: 0.6008 - val_auc: 0.7045 - val_prec: 0.7826 - val_rec: 0.4737 - val_vector_accuracy: 0.6894\n",
      "Epoch 15/100\n",
      "6/6 [==============================] - 2s 415ms/step - loss: 0.6246 - auc: 0.6716 - prec: 0.7133 - rec: 0.4603 - vector_accuracy: 0.6515 - val_loss: 0.6021 - val_auc: 0.7045 - val_prec: 0.7826 - val_rec: 0.4737 - val_vector_accuracy: 0.6894\n",
      "Epoch 16/100\n",
      "6/6 [==============================] - 3s 438ms/step - loss: 0.6259 - auc: 0.6533 - prec: 0.7415 - rec: 0.4417 - vector_accuracy: 0.6573 - val_loss: 0.6047 - val_auc: 0.7045 - val_prec: 0.7826 - val_rec: 0.4737 - val_vector_accuracy: 0.6894\n",
      "Epoch 17/100\n",
      "6/6 [==============================] - 2s 387ms/step - loss: 0.6251 - auc: 0.6563 - prec: 0.7408 - rec: 0.4401 - vector_accuracy: 0.6569 - val_loss: 0.6046 - val_auc: 0.7045 - val_prec: 0.7826 - val_rec: 0.4737 - val_vector_accuracy: 0.6894\n",
      "Epoch 18/100\n",
      "6/6 [==============================] - 2s 411ms/step - loss: 0.6248 - auc: 0.6699 - prec: 0.7408 - rec: 0.4401 - vector_accuracy: 0.6566 - val_loss: 0.6030 - val_auc: 0.7045 - val_prec: 0.7826 - val_rec: 0.4737 - val_vector_accuracy: 0.6894\n",
      "Epoch 19/100\n",
      "6/6 [==============================] - 2s 378ms/step - loss: 0.6245 - auc: 0.6720 - prec: 0.7370 - rec: 0.4401 - vector_accuracy: 0.6550 - val_loss: 0.6017 - val_auc: 0.7045 - val_prec: 0.7826 - val_rec: 0.4737 - val_vector_accuracy: 0.6894\n",
      "Epoch 20/100\n",
      "6/6 [==============================] - 2s 415ms/step - loss: 0.6244 - auc: 0.6692 - prec: 0.7415 - rec: 0.4417 - vector_accuracy: 0.6575 - val_loss: 0.6029 - val_auc: 0.7045 - val_prec: 0.7826 - val_rec: 0.4737 - val_vector_accuracy: 0.6894\n",
      "Epoch 21/100\n",
      "6/6 [==============================] - 2s 401ms/step - loss: 0.6248 - auc: 0.6616 - prec: 0.7408 - rec: 0.4401 - vector_accuracy: 0.6565 - val_loss: 0.6020 - val_auc: 0.7045 - val_prec: 0.7826 - val_rec: 0.4737 - val_vector_accuracy: 0.6894\n",
      "Epoch 22/100\n",
      "6/6 [==============================] - 2s 416ms/step - loss: 0.6250 - auc: 0.6638 - prec: 0.7408 - rec: 0.4401 - vector_accuracy: 0.6564 - val_loss: 0.6025 - val_auc: 0.7045 - val_prec: 0.7826 - val_rec: 0.4737 - val_vector_accuracy: 0.6894\n",
      "Epoch 23/100\n",
      "6/6 [==============================] - 2s 387ms/step - loss: 0.6244 - auc: 0.6693 - prec: 0.7408 - rec: 0.4401 - vector_accuracy: 0.6566 - val_loss: 0.6029 - val_auc: 0.7045 - val_prec: 0.7826 - val_rec: 0.4737 - val_vector_accuracy: 0.6894\n",
      "Epoch 24/100\n",
      "6/6 [==============================] - 2s 417ms/step - loss: 0.6245 - auc: 0.6705 - prec: 0.7408 - rec: 0.4401 - vector_accuracy: 0.6570 - val_loss: 0.6030 - val_auc: 0.7045 - val_prec: 0.7826 - val_rec: 0.4737 - val_vector_accuracy: 0.6894\n",
      "Epoch 25/100\n",
      "6/6 [==============================] - 2s 411ms/step - loss: 0.6247 - auc: 0.6719 - prec: 0.7378 - rec: 0.4463 - vector_accuracy: 0.6573 - val_loss: 0.6032 - val_auc: 0.7045 - val_prec: 0.7826 - val_rec: 0.4737 - val_vector_accuracy: 0.6894\n",
      "Epoch 26/100\n",
      "6/6 [==============================] - 3s 432ms/step - loss: 0.6248 - auc: 0.6566 - prec: 0.7129 - rec: 0.4712 - vector_accuracy: 0.6544 - val_loss: 0.6034 - val_auc: 0.7045 - val_prec: 0.7826 - val_rec: 0.4737 - val_vector_accuracy: 0.6894\n",
      "Epoch 27/100\n",
      "6/6 [==============================] - 3s 428ms/step - loss: 0.6245 - auc: 0.6661 - prec: 0.7316 - rec: 0.4495 - vector_accuracy: 0.6559 - val_loss: 0.6031 - val_auc: 0.7045 - val_prec: 0.7826 - val_rec: 0.4737 - val_vector_accuracy: 0.6894\n",
      "Epoch 28/100\n",
      "6/6 [==============================] - 2s 392ms/step - loss: 0.6248 - auc: 0.6623 - prec: 0.7408 - rec: 0.4401 - vector_accuracy: 0.6567 - val_loss: 0.6031 - val_auc: 0.7045 - val_prec: 0.7826 - val_rec: 0.4737 - val_vector_accuracy: 0.6894\n",
      "Epoch 29/100\n",
      "6/6 [==============================] - 2s 388ms/step - loss: 0.6250 - auc: 0.6494 - prec: 0.7408 - rec: 0.4401 - vector_accuracy: 0.6568 - val_loss: 0.6036 - val_auc: 0.7045 - val_prec: 0.7826 - val_rec: 0.4737 - val_vector_accuracy: 0.6894\n",
      "Epoch 30/100\n",
      "6/6 [==============================] - 2s 392ms/step - loss: 0.6246 - auc: 0.6718 - prec: 0.7408 - rec: 0.4401 - vector_accuracy: 0.6565 - val_loss: 0.6028 - val_auc: 0.7045 - val_prec: 0.7826 - val_rec: 0.4737 - val_vector_accuracy: 0.6894\n",
      "Epoch 31/100\n",
      "6/6 [==============================] - 2s 374ms/step - loss: 0.6245 - auc: 0.6615 - prec: 0.7408 - rec: 0.4401 - vector_accuracy: 0.6565 - val_loss: 0.6016 - val_auc: 0.7045 - val_prec: 0.7826 - val_rec: 0.4737 - val_vector_accuracy: 0.6894\n",
      "Epoch 32/100\n",
      "6/6 [==============================] - 2s 388ms/step - loss: 0.6247 - auc: 0.6727 - prec: 0.7408 - rec: 0.4401 - vector_accuracy: 0.6566 - val_loss: 0.6009 - val_auc: 0.7045 - val_prec: 0.7826 - val_rec: 0.4737 - val_vector_accuracy: 0.6894\n",
      "Epoch 33/100\n",
      "6/6 [==============================] - 2s 398ms/step - loss: 0.6246 - auc: 0.6644 - prec: 0.7408 - rec: 0.4401 - vector_accuracy: 0.6569 - val_loss: 0.6022 - val_auc: 0.7045 - val_prec: 0.7826 - val_rec: 0.4737 - val_vector_accuracy: 0.6894\n",
      "Epoch 34/100\n",
      "6/6 [==============================] - 2s 376ms/step - loss: 0.6246 - auc: 0.6642 - prec: 0.7408 - rec: 0.4401 - vector_accuracy: 0.6569 - val_loss: 0.6032 - val_auc: 0.7045 - val_prec: 0.7826 - val_rec: 0.4737 - val_vector_accuracy: 0.6894\n",
      "Epoch 35/100\n",
      "6/6 [==============================] - 2s 405ms/step - loss: 0.6246 - auc: 0.6695 - prec: 0.7408 - rec: 0.4401 - vector_accuracy: 0.6568 - val_loss: 0.6033 - val_auc: 0.7045 - val_prec: 0.7826 - val_rec: 0.4737 - val_vector_accuracy: 0.6894\n",
      "Epoch 36/100\n",
      "6/6 [==============================] - 2s 375ms/step - loss: 0.6248 - auc: 0.6663 - prec: 0.7408 - rec: 0.4401 - vector_accuracy: 0.6566 - val_loss: 0.6025 - val_auc: 0.7045 - val_prec: 0.7826 - val_rec: 0.4737 - val_vector_accuracy: 0.6894\n",
      "Epoch 37/100\n",
      "6/6 [==============================] - 2s 388ms/step - loss: 0.6245 - auc: 0.6745 - prec: 0.7408 - rec: 0.4401 - vector_accuracy: 0.6566 - val_loss: 0.6019 - val_auc: 0.7045 - val_prec: 0.7826 - val_rec: 0.4737 - val_vector_accuracy: 0.6894\n",
      "Epoch 38/100\n",
      "6/6 [==============================] - 2s 392ms/step - loss: 0.6248 - auc: 0.6624 - prec: 0.7408 - rec: 0.4401 - vector_accuracy: 0.6567 - val_loss: 0.6022 - val_auc: 0.7045 - val_prec: 0.7826 - val_rec: 0.4737 - val_vector_accuracy: 0.6894\n",
      "Epoch 39/100\n",
      "6/6 [==============================] - 2s 398ms/step - loss: 0.6245 - auc: 0.6626 - prec: 0.7408 - rec: 0.4401 - vector_accuracy: 0.6566 - val_loss: 0.6024 - val_auc: 0.7045 - val_prec: 0.7826 - val_rec: 0.4737 - val_vector_accuracy: 0.6894\n",
      "Epoch 40/100\n",
      "6/6 [==============================] - 2s 397ms/step - loss: 0.6245 - auc: 0.6697 - prec: 0.7408 - rec: 0.4401 - vector_accuracy: 0.6568 - val_loss: 0.6028 - val_auc: 0.7045 - val_prec: 0.7826 - val_rec: 0.4737 - val_vector_accuracy: 0.6894\n",
      "Epoch 41/100\n",
      "6/6 [==============================] - 2s 419ms/step - loss: 0.6246 - auc: 0.6651 - prec: 0.7408 - rec: 0.4401 - vector_accuracy: 0.6567 - val_loss: 0.6026 - val_auc: 0.7045 - val_prec: 0.7826 - val_rec: 0.4737 - val_vector_accuracy: 0.6894\n",
      "Epoch 42/100\n",
      "6/6 [==============================] - 3s 421ms/step - loss: 0.6243 - auc: 0.6781 - prec: 0.7408 - rec: 0.4401 - vector_accuracy: 0.6566 - val_loss: 0.6031 - val_auc: 0.7045 - val_prec: 0.7826 - val_rec: 0.4737 - val_vector_accuracy: 0.6894\n",
      "Epoch 43/100\n",
      "6/6 [==============================] - 2s 375ms/step - loss: 0.6246 - auc: 0.6691 - prec: 0.7408 - rec: 0.4401 - vector_accuracy: 0.6564 - val_loss: 0.6023 - val_auc: 0.7045 - val_prec: 0.7826 - val_rec: 0.4737 - val_vector_accuracy: 0.6894\n",
      "Epoch 44/100\n",
      "6/6 [==============================] - 2s 376ms/step - loss: 0.6244 - auc: 0.6679 - prec: 0.7408 - rec: 0.4401 - vector_accuracy: 0.6567 - val_loss: 0.6030 - val_auc: 0.7045 - val_prec: 0.7826 - val_rec: 0.4737 - val_vector_accuracy: 0.6894\n",
      "Epoch 45/100\n",
      "6/6 [==============================] - 2s 376ms/step - loss: 0.6244 - auc: 0.6810 - prec: 0.7408 - rec: 0.4401 - vector_accuracy: 0.6568 - val_loss: 0.6024 - val_auc: 0.7045 - val_prec: 0.7826 - val_rec: 0.4737 - val_vector_accuracy: 0.6894\n",
      "Epoch 46/100\n",
      "6/6 [==============================] - 2s 389ms/step - loss: 0.6247 - auc: 0.6583 - prec: 0.7408 - rec: 0.4401 - vector_accuracy: 0.6565 - val_loss: 0.6022 - val_auc: 0.7045 - val_prec: 0.7826 - val_rec: 0.4737 - val_vector_accuracy: 0.6894\n",
      "Epoch 47/100\n",
      "6/6 [==============================] - 2s 404ms/step - loss: 0.6243 - auc: 0.6764 - prec: 0.7408 - rec: 0.4401 - vector_accuracy: 0.6569 - val_loss: 0.6016 - val_auc: 0.7045 - val_prec: 0.7826 - val_rec: 0.4737 - val_vector_accuracy: 0.6894\n",
      "Epoch 48/100\n",
      "6/6 [==============================] - 2s 400ms/step - loss: 0.6248 - auc: 0.6662 - prec: 0.7408 - rec: 0.4401 - vector_accuracy: 0.6567 - val_loss: 0.6034 - val_auc: 0.7045 - val_prec: 0.7826 - val_rec: 0.4737 - val_vector_accuracy: 0.6894\n",
      "Epoch 49/100\n",
      "6/6 [==============================] - 2s 386ms/step - loss: 0.6243 - auc: 0.6736 - prec: 0.7408 - rec: 0.4401 - vector_accuracy: 0.6567 - val_loss: 0.6035 - val_auc: 0.7045 - val_prec: 0.7826 - val_rec: 0.4737 - val_vector_accuracy: 0.6894\n",
      "Epoch 50/100\n",
      "6/6 [==============================] - 2s 399ms/step - loss: 0.6247 - auc: 0.6683 - prec: 0.7408 - rec: 0.4401 - vector_accuracy: 0.6567 - val_loss: 0.6015 - val_auc: 0.7045 - val_prec: 0.7826 - val_rec: 0.4737 - val_vector_accuracy: 0.6894\n",
      "Epoch 51/100\n",
      "6/6 [==============================] - 2s 376ms/step - loss: 0.6245 - auc: 0.6735 - prec: 0.7408 - rec: 0.4401 - vector_accuracy: 0.6567 - val_loss: 0.6013 - val_auc: 0.7045 - val_prec: 0.7826 - val_rec: 0.4737 - val_vector_accuracy: 0.6894\n",
      "Epoch 52/100\n",
      "6/6 [==============================] - 2s 375ms/step - loss: 0.6245 - auc: 0.6718 - prec: 0.7408 - rec: 0.4401 - vector_accuracy: 0.6568 - val_loss: 0.6024 - val_auc: 0.7045 - val_prec: 0.7826 - val_rec: 0.4737 - val_vector_accuracy: 0.6894\n",
      "Epoch 53/100\n",
      "6/6 [==============================] - 2s 377ms/step - loss: 0.6245 - auc: 0.6633 - prec: 0.7408 - rec: 0.4401 - vector_accuracy: 0.6569 - val_loss: 0.6036 - val_auc: 0.7045 - val_prec: 0.7826 - val_rec: 0.4737 - val_vector_accuracy: 0.6894\n",
      "Epoch 54/100\n",
      "6/6 [==============================] - 2s 375ms/step - loss: 0.6244 - auc: 0.6697 - prec: 0.7408 - rec: 0.4401 - vector_accuracy: 0.6566 - val_loss: 0.6036 - val_auc: 0.7045 - val_prec: 0.7826 - val_rec: 0.4737 - val_vector_accuracy: 0.6894\n",
      "Epoch 55/100\n",
      "6/6 [==============================] - 2s 390ms/step - loss: 0.6244 - auc: 0.6683 - prec: 0.7408 - rec: 0.4401 - vector_accuracy: 0.6568 - val_loss: 0.6025 - val_auc: 0.7045 - val_prec: 0.7826 - val_rec: 0.4737 - val_vector_accuracy: 0.6894\n",
      "Epoch 56/100\n",
      "6/6 [==============================] - 2s 423ms/step - loss: 0.6246 - auc: 0.6744 - prec: 0.7408 - rec: 0.4401 - vector_accuracy: 0.6567 - val_loss: 0.6018 - val_auc: 0.7045 - val_prec: 0.7826 - val_rec: 0.4737 - val_vector_accuracy: 0.6894\n",
      "Epoch 57/100\n",
      "6/6 [==============================] - 2s 402ms/step - loss: 0.6256 - auc: 0.6558 - prec: 0.7326 - rec: 0.4432 - vector_accuracy: 0.6546 - val_loss: 0.6010 - val_auc: 0.7045 - val_prec: 0.7826 - val_rec: 0.4737 - val_vector_accuracy: 0.6894\n",
      "Epoch 58/100\n",
      "6/6 [==============================] - 2s 403ms/step - loss: 0.6250 - auc: 0.6668 - prec: 0.7389 - rec: 0.4401 - vector_accuracy: 0.6559 - val_loss: 0.6027 - val_auc: 0.7045 - val_prec: 0.7826 - val_rec: 0.4737 - val_vector_accuracy: 0.6894\n",
      "Epoch 59/100\n",
      "6/6 [==============================] - 2s 375ms/step - loss: 0.6246 - auc: 0.6634 - prec: 0.7408 - rec: 0.4401 - vector_accuracy: 0.6567 - val_loss: 0.6034 - val_auc: 0.7045 - val_prec: 0.7826 - val_rec: 0.4737 - val_vector_accuracy: 0.6894\n",
      "Epoch 60/100\n",
      "6/6 [==============================] - 2s 402ms/step - loss: 0.6245 - auc: 0.6712 - prec: 0.7408 - rec: 0.4401 - vector_accuracy: 0.6566 - val_loss: 0.6025 - val_auc: 0.7045 - val_prec: 0.7826 - val_rec: 0.4737 - val_vector_accuracy: 0.6894\n",
      "Epoch 61/100\n",
      "1/6 [====>.........................] - ETA: 1s - loss: 0.6651 - auc: 0.6339 - prec: 0.6719 - rec: 0.3772 - vector_accuracy: 0.5893"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/mnt/pool1/research/email-classifier/scripts_cues/cues_006.ipynb Cell 6\u001b[0m line \u001b[0;36m1\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22686f6d656c6162222c2275736572223a226173686b616e227d/mnt/pool1/research/email-classifier/scripts_cues/cues_006.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=147'>148</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m model \n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22686f6d656c6162222c2275736572223a226173686b616e227d/mnt/pool1/research/email-classifier/scripts_cues/cues_006.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=149'>150</a>\u001b[0m multilabel_model \u001b[39m=\u001b[39m build_model(\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22686f6d656c6162222c2275736572223a226173686b616e227d/mnt/pool1/research/email-classifier/scripts_cues/cues_006.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=150'>151</a>\u001b[0m     subject_length \u001b[39m=\u001b[39m SUBJECT_LEN,\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22686f6d656c6162222c2275736572223a226173686b616e227d/mnt/pool1/research/email-classifier/scripts_cues/cues_006.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=151'>152</a>\u001b[0m     body_length \u001b[39m=\u001b[39m BODY_LEN,\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22686f6d656c6162222c2275736572223a226173686b616e227d/mnt/pool1/research/email-classifier/scripts_cues/cues_006.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=152'>153</a>\u001b[0m     embedding \u001b[39m=\u001b[39m embedding,\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22686f6d656c6162222c2275736572223a226173686b616e227d/mnt/pool1/research/email-classifier/scripts_cues/cues_006.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=153'>154</a>\u001b[0m     num_factors \u001b[39m=\u001b[39m NUM_FACTORS\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22686f6d656c6162222c2275736572223a226173686b616e227d/mnt/pool1/research/email-classifier/scripts_cues/cues_006.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=154'>155</a>\u001b[0m )\n\u001b[0;32m--> <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22686f6d656c6162222c2275736572223a226173686b616e227d/mnt/pool1/research/email-classifier/scripts_cues/cues_006.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=156'>157</a>\u001b[0m multilabel_model \u001b[39m=\u001b[39m train_and_evaluate(\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22686f6d656c6162222c2275736572223a226173686b616e227d/mnt/pool1/research/email-classifier/scripts_cues/cues_006.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=157'>158</a>\u001b[0m     model \u001b[39m=\u001b[39;49m multilabel_model,\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22686f6d656c6162222c2275736572223a226173686b616e227d/mnt/pool1/research/email-classifier/scripts_cues/cues_006.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=158'>159</a>\u001b[0m     train_ds \u001b[39m=\u001b[39;49m ([train_email_titles, train_email_bodies], train_y),\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22686f6d656c6162222c2275736572223a226173686b616e227d/mnt/pool1/research/email-classifier/scripts_cues/cues_006.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=159'>160</a>\u001b[0m     test_ds \u001b[39m=\u001b[39;49m ([test_email_titles, test_email_bodies], test_y),\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22686f6d656c6162222c2275736572223a226173686b616e227d/mnt/pool1/research/email-classifier/scripts_cues/cues_006.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=160'>161</a>\u001b[0m     valid_ds \u001b[39m=\u001b[39;49m ([valid_email_titles, valid_email_bodies], valid_y),\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22686f6d656c6162222c2275736572223a226173686b616e227d/mnt/pool1/research/email-classifier/scripts_cues/cues_006.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=161'>162</a>\u001b[0m     epochs \u001b[39m=\u001b[39;49m \u001b[39m100\u001b[39;49m, \u001b[39m# IXME: was 50 before visualizations\u001b[39;49;00m\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22686f6d656c6162222c2275736572223a226173686b616e227d/mnt/pool1/research/email-classifier/scripts_cues/cues_006.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=162'>163</a>\u001b[0m     batch_size \u001b[39m=\u001b[39;49m \u001b[39m32\u001b[39;49m,\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22686f6d656c6162222c2275736572223a226173686b616e227d/mnt/pool1/research/email-classifier/scripts_cues/cues_006.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=163'>164</a>\u001b[0m     attributes \u001b[39m=\u001b[39;49m attributes,\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22686f6d656c6162222c2275736572223a226173686b616e227d/mnt/pool1/research/email-classifier/scripts_cues/cues_006.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=164'>165</a>\u001b[0m )\n",
      "\u001b[1;32m/mnt/pool1/research/email-classifier/scripts_cues/cues_006.ipynb Cell 6\u001b[0m line \u001b[0;36m1\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22686f6d656c6162222c2275736572223a226173686b616e227d/mnt/pool1/research/email-classifier/scripts_cues/cues_006.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=165'>166</a>\u001b[0m \u001b[39mprint\u001b[39m(model\u001b[39m.\u001b[39msummary())\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22686f6d656c6162222c2275736572223a226173686b616e227d/mnt/pool1/research/email-classifier/scripts_cues/cues_006.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=167'>168</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mtype\u001b[39m(train_ds) \u001b[39mis\u001b[39;00m \u001b[39mtuple\u001b[39m:\n\u001b[0;32m--> <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22686f6d656c6162222c2275736572223a226173686b616e227d/mnt/pool1/research/email-classifier/scripts_cues/cues_006.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=168'>169</a>\u001b[0m     history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22686f6d656c6162222c2275736572223a226173686b616e227d/mnt/pool1/research/email-classifier/scripts_cues/cues_006.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=169'>170</a>\u001b[0m         train_ds[\u001b[39m0\u001b[39;49m], \u001b[39m# x: \u001b[39;49;00m\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22686f6d656c6162222c2275736572223a226173686b616e227d/mnt/pool1/research/email-classifier/scripts_cues/cues_006.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=170'>171</a>\u001b[0m         train_ds[\u001b[39m1\u001b[39;49m], \u001b[39m# y\u001b[39;49;00m\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22686f6d656c6162222c2275736572223a226173686b616e227d/mnt/pool1/research/email-classifier/scripts_cues/cues_006.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=171'>172</a>\u001b[0m         validation_data \u001b[39m=\u001b[39;49m valid_ds, \u001b[39m# tuples are allowed, ignored if none\u001b[39;49;00m\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22686f6d656c6162222c2275736572223a226173686b616e227d/mnt/pool1/research/email-classifier/scripts_cues/cues_006.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=172'>173</a>\u001b[0m         epochs \u001b[39m=\u001b[39;49m epochs,\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22686f6d656c6162222c2275736572223a226173686b616e227d/mnt/pool1/research/email-classifier/scripts_cues/cues_006.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=173'>174</a>\u001b[0m         batch_size \u001b[39m=\u001b[39;49m batch_size\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22686f6d656c6162222c2275736572223a226173686b616e227d/mnt/pool1/research/email-classifier/scripts_cues/cues_006.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=174'>175</a>\u001b[0m     )\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22686f6d656c6162222c2275736572223a226173686b616e227d/mnt/pool1/research/email-classifier/scripts_cues/cues_006.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=175'>176</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22686f6d656c6162222c2275736572223a226173686b616e227d/mnt/pool1/research/email-classifier/scripts_cues/cues_006.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=176'>177</a>\u001b[0m     history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mfit(\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22686f6d656c6162222c2275736572223a226173686b616e227d/mnt/pool1/research/email-classifier/scripts_cues/cues_006.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=177'>178</a>\u001b[0m         train_ds,\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22686f6d656c6162222c2275736572223a226173686b616e227d/mnt/pool1/research/email-classifier/scripts_cues/cues_006.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=178'>179</a>\u001b[0m         validation_data\u001b[39m=\u001b[39mvalid_ds,  \u001b[39m# ignored if None\u001b[39;00m\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22686f6d656c6162222c2275736572223a226173686b616e227d/mnt/pool1/research/email-classifier/scripts_cues/cues_006.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=179'>180</a>\u001b[0m         epochs\u001b[39m=\u001b[39mepochs,\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22686f6d656c6162222c2275736572223a226173686b616e227d/mnt/pool1/research/email-classifier/scripts_cues/cues_006.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=180'>181</a>\u001b[0m         batch_size \u001b[39m=\u001b[39m batch_size\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22686f6d656c6162222c2275736572223a226173686b616e227d/mnt/pool1/research/email-classifier/scripts_cues/cues_006.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=181'>182</a>\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/keras/src/engine/training.py:1742\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1734\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[1;32m   1735\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   1736\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1739\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[1;32m   1740\u001b[0m ):\n\u001b[1;32m   1741\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1742\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[1;32m   1743\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[1;32m   1744\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:825\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    822\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    824\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 825\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    827\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    828\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:857\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    854\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m    855\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    856\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 857\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_no_variable_creation_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    858\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_variable_creation_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    859\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    860\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[1;32m    861\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:148\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m    146\u001b[0m   (concrete_function,\n\u001b[1;32m    147\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m--> 148\u001b[0m \u001b[39mreturn\u001b[39;00m concrete_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[1;32m    149\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mconcrete_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:1349\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs)\u001b[0m\n\u001b[1;32m   1345\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1346\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1347\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1348\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1349\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function(\u001b[39m*\u001b[39;49margs))\n\u001b[1;32m   1350\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1351\u001b[0m     args,\n\u001b[1;32m   1352\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1353\u001b[0m     executing_eagerly)\n\u001b[1;32m   1354\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:196\u001b[0m, in \u001b[0;36mAtomicFunction.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[39mwith\u001b[39;00m record\u001b[39m.\u001b[39mstop_recording():\n\u001b[1;32m    195\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_bound_context\u001b[39m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 196\u001b[0m     outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_bound_context\u001b[39m.\u001b[39;49mcall_function(\n\u001b[1;32m    197\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname,\n\u001b[1;32m    198\u001b[0m         \u001b[39mlist\u001b[39;49m(args),\n\u001b[1;32m    199\u001b[0m         \u001b[39mlen\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunction_type\u001b[39m.\u001b[39;49mflat_outputs),\n\u001b[1;32m    200\u001b[0m     )\n\u001b[1;32m    201\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    202\u001b[0m     outputs \u001b[39m=\u001b[39m make_call_op_in_graph(\u001b[39mself\u001b[39m, \u001b[39mlist\u001b[39m(args))\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/context.py:1457\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1455\u001b[0m cancellation_context \u001b[39m=\u001b[39m cancellation\u001b[39m.\u001b[39mcontext()\n\u001b[1;32m   1456\u001b[0m \u001b[39mif\u001b[39;00m cancellation_context \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1457\u001b[0m   outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[1;32m   1458\u001b[0m       name\u001b[39m.\u001b[39;49mdecode(\u001b[39m\"\u001b[39;49m\u001b[39mutf-8\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m   1459\u001b[0m       num_outputs\u001b[39m=\u001b[39;49mnum_outputs,\n\u001b[1;32m   1460\u001b[0m       inputs\u001b[39m=\u001b[39;49mtensor_inputs,\n\u001b[1;32m   1461\u001b[0m       attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[1;32m   1462\u001b[0m       ctx\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[1;32m   1463\u001b[0m   )\n\u001b[1;32m   1464\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1465\u001b[0m   outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1466\u001b[0m       name\u001b[39m.\u001b[39mdecode(\u001b[39m\"\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[1;32m   1467\u001b[0m       num_outputs\u001b[39m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1471\u001b[0m       cancellation_manager\u001b[39m=\u001b[39mcancellation_context,\n\u001b[1;32m   1472\u001b[0m   )\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[1;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "### transformer-model, after watching coursera! ###\n",
    "\n",
    "# create datasets\n",
    "batch_size = 32\n",
    "\n",
    "# sorry for the ugly code\n",
    "[[train_email_titles, train_email_bodies, train_y],\n",
    "[valid_email_titles, valid_email_bodies, valid_y],\n",
    "[test_email_titles, test_email_bodies, test_y]] = train_valid_test_split([email_titles, email_bodies, email_types], 0.8, 0.1, 32)\n",
    "\n",
    "# transformer block: https://keras.io/examples/nlp/text_classification_with_transformer/\n",
    "class TransformerEncoder(layers.Layer):\n",
    "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1):\n",
    "        super().__init__()\n",
    "        self.att = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
    "        self.ffn = keras.Sequential( # feedforward layer. uses sequential to group them together\n",
    "            [layers.Dense(ff_dim, activation=\"relu\"), layers.Dense(embed_dim),]\n",
    "        )\n",
    "        self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.dropout1 = layers.Dropout(rate)\n",
    "        self.dropout2 = layers.Dropout(rate)\n",
    "\n",
    "    def call(self, inputs, training):\n",
    "        attn_output = self.att(inputs, inputs) # target, source\n",
    "        attn_output = self.dropout1(attn_output, training=training)\n",
    "        out1 = self.layernorm1(inputs + attn_output) # add & norm\n",
    "        ffn_output = self.ffn(out1)\n",
    "        ffn_output = self.dropout2(ffn_output, training=training)\n",
    "        return self.layernorm2(out1 + ffn_output) # add & norm\n",
    "    \n",
    "# this handles the word embedding from scratch. \n",
    "# I'm using a pretrained embedding so I'll remove that\n",
    "class TokenAndPositionEmbedding(layers.Layer):\n",
    "    def __init__(self, maxlen, vocab_size, embed_dim):\n",
    "        super().__init__()\n",
    "        self.token_emb = layers.Embedding(input_dim=vocab_size, output_dim=embed_dim)\n",
    "        self.pos_emb = layers.Embedding(input_dim=maxlen, output_dim=embed_dim)\n",
    "\n",
    "    def call(self, x):\n",
    "        maxlen = tf.shape(x)[-1]\n",
    "        positions = tf.range(start=0, limit=maxlen, delta=1)\n",
    "        positions = self.pos_emb(positions)\n",
    "        x = self.token_emb(x)\n",
    "        return x + positions\n",
    "\n",
    "# custom: only adds positional embedding\n",
    "class PositionEmbedding(layers.Layer):\n",
    "    def __init__(self, maxlen, embed_dim):\n",
    "        super().__init__()\n",
    "        self.pos_emb = layers.Embedding(input_dim=maxlen, output_dim=embed_dim)\n",
    "\n",
    "    def call(self, x):\n",
    "        maxlen = tf.shape(x)[-1]\n",
    "        positions = tf.range(start=0, limit=maxlen, delta=1)\n",
    "        positions = self.pos_emb(positions)\n",
    "        return x + positions\n",
    "\n",
    "# create model\n",
    "def build_model(subject_length, body_length, embedding, num_factors):\n",
    "    # inputs\n",
    "    subjectInput = layers.Input(shape = (subject_length,))\n",
    "    bodyInput = layers.Input(shape = (body_length,))\n",
    "    \n",
    "    # subject analysis \n",
    "    x_subj = pretrained_embedding(embedding)(subjectInput) # DON'T CHANGE\n",
    "    x_subj = layers.BatchNormalization()(x_subj)\n",
    "    # single directional GRU should be enough\n",
    "    x_subj = layers.GRU(subject_length)(x_subj)\n",
    "    # note: for GRU, the default tanh activation is highly optimized for GPU. uses cudnn\n",
    "    x_subj = layers.Dense(4, activation = 'relu')(x_subj) # very sus\n",
    "\n",
    "    # # subject analysis\n",
    "    # x_subj = pretrained_embedding(embedding)(subjectInput)\n",
    "    # x_subj = layers.BatchNormalization()(x_subj)\n",
    "    # x_subj = layers.Bidirectional(\n",
    "    #     layers.GRU(subject_length)\n",
    "    # )(x_subj)\n",
    "    # x_subj = layers.Dense(4, activation = 'relu')(x_subj)\n",
    "\n",
    "    # # body analysis\n",
    "    # x_body = pretrained_embedding(embedding)(bodyInput)\n",
    "    # x_body = layers.BatchNormalization()(x_body)\n",
    "    # x_body = layers.Bidirectional(\n",
    "    #     layers.GRU(body_length)\n",
    "    # )(x_body)\n",
    "    # x_body = layers.Dense(32, activation = 'relu')(x_body)\n",
    "\n",
    "    # transformer body analysis\n",
    "    # these two are problematic vv\n",
    "    # x_body = pretrained_embedding(embedding)(bodyInput) # DON'T CHANGE\n",
    "    # x_body = PositionEmbedding(maxlen = BODY_LEN, embed_dim = 50)(x_body)\n",
    "    x_body = TokenAndPositionEmbedding(maxlen = body_length, vocab_size = len(embedding), embed_dim=50)(bodyInput)\n",
    "    # it's suggested that the encoder be repeated...\n",
    "    x_body = TransformerEncoder(embed_dim = 50, num_heads = 128, ff_dim = 32)(x_body) \n",
    "    # x_body = TransformerEncoder(embed_dim = 50, num_heads = 128, ff_dim = 32)(x_body) \n",
    "    # x_body = TransformerEncoder(embed_dim = 50, num_heads = 128, ff_dim = 32)(x_body) \n",
    "    # x_body = TransformerEncoder(embed_dim = 50, num_heads = 128, ff_dim = 32)(x_body) \n",
    "    # x_body = TransformerEncoder(embed_dim = 50, num_heads = 128, ff_dim = 32)(x_body) \n",
    "    # x_body = TransformerEncoder(embed_dim = 50, num_heads = 128, ff_dim = 32)(x_body)\n",
    "    # x_body.shape = ([none, 80, 50])\n",
    "    # HYPER: ff_dim \n",
    "    # TODO: ff_dim 32 literally copied from the guide. I'm not sure about the effect\n",
    "    # x_body = layers.GlobalAveragePooling1D()(x_body) # TODO: no idea what this does either\n",
    "    # x_body = layers.Dropout(0.1)(x_body)\n",
    "    # x_body = layers.Dense(32, activation = 'relu')(x_body)\n",
    "    # x_body = layers.Dropout(0.1)(x_body)\n",
    "    x_body = layers.GRU(subject_length)(x_body)\n",
    "    x_body = layers.Dense(32)(x_body)\n",
    "\n",
    "    # stitch them together...\n",
    "    x = layers.Concatenate()([x_subj, x_body]) \n",
    "    x = layers.Dropout(0.5)(x_body) \n",
    "    x = layers.Dense(64, activation = 'relu')(x)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    x = layers.Dense(num_factors, activation = 'sigmoid')(x_body) # from logits true will automatically add the sigmoid\n",
    "\n",
    "    model = keras.models.Model(\n",
    "        inputs = [subjectInput, bodyInput],\n",
    "        outputs = x,\n",
    "    )\n",
    "\n",
    "    model.compile(\n",
    "        loss=keras.losses.BinaryCrossentropy(from_logits = False),\n",
    "        optimizer=keras.optimizers.Adam(\n",
    "            learning_rate=0.001\n",
    "        ),\n",
    "        metrics=[\n",
    "            # 'acc', # DOES NOT WORK CORRECTLY WITH MATRICES\n",
    "            # pr curve area - should help with imbalanced data\n",
    "            keras.metrics.AUC(curve='PR', name='auc'),\n",
    "            # keras.metrics.TruePositives(name = 'tp'),\n",
    "            # keras.metrics.FalsePositives(name = 'fp'),\n",
    "            # keras.metrics.TrueNegatives(name = 'tn'),\n",
    "            # keras.metrics.FalseNegatives(name = 'fn'),\n",
    "            keras.metrics.Precision(name='prec'),\n",
    "            keras.metrics.Recall(name='rec'),\n",
    "            vector_accuracy,\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    return model \n",
    "\n",
    "multilabel_model = build_model(\n",
    "    subject_length = SUBJECT_LEN,\n",
    "    body_length = BODY_LEN,\n",
    "    embedding = embedding,\n",
    "    num_factors = NUM_FACTORS\n",
    ")\n",
    "\n",
    "multilabel_model = train_and_evaluate(\n",
    "    model = multilabel_model,\n",
    "    train_ds = ([train_email_titles, train_email_bodies], train_y),\n",
    "    test_ds = ([test_email_titles, test_email_bodies], test_y),\n",
    "    valid_ds = ([valid_email_titles, valid_email_bodies], valid_y),\n",
    "    epochs = 100, # IXME: was 50 before visualizations\n",
    "    batch_size = 32,\n",
    "    attributes = attributes,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# type((train_x, train_y)) is tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
